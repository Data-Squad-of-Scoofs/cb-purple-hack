{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16abcbb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7869\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7869/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import clickhouse_connect\n",
    "from embedding import E5LargeEmbeddingFunction\n",
    "from similarity import bm25_ensemble_with_crossenc_answer, prep_query, bm25_fewshot_with_cross_encoder\n",
    "from pprint import pprint\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import gc\n",
    "\n",
    "\n",
    "client = clickhouse_connect.get_client(host='y1jzidyt9q.us-east-2.aws.clickhouse.cloud', port=8443, username='default', password='_lQ_JWXYQD3ym')\n",
    "emb_func = E5LargeEmbeddingFunction()\n",
    "\n",
    "def message_llm(system_prompt, user_input, temperature=0.6):\n",
    "    '''Function to message (test) our LLM'''\n",
    "\n",
    "    try:\n",
    "        url = \"https://live-relaxed-oryx.ngrok-free.app/v1/chat/completions\"\n",
    "\n",
    "        data = {\n",
    "          \"messages\": [\n",
    "            { \"role\": \"system\", \"content\": system_prompt},\n",
    "            { \"role\": \"user\", \"content\": user_input}\n",
    "          ],\n",
    "          \"temperature\": 0.6,\n",
    "          # \"max_tokens\": -1,\n",
    "          # \"stream\": False\n",
    "        }\n",
    "\n",
    "        headers = {\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "\n",
    "        response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            return eval(response.text.replace(\"\\n  \", \"\"))['choices'][0]['message']['content']\n",
    "        else:\n",
    "            print(\"Ошибка запроса:\\n\", response.status_code, response.text)\n",
    "            return \"\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        \n",
    "        print(f\"Error {e}!\")\n",
    "        \n",
    "rag_prompt = \"\"\"\n",
    "### CONTEXT ###\n",
    "1) ИСТОЧНИК 1: \n",
    "- {type_of_source1}\n",
    "- {link_to_source1}\n",
    "- {batch_1}\n",
    "\n",
    "2) ИСТОЧНИК 2: \n",
    "- {type_of_source2}\n",
    "- {link_to_source2}\n",
    "- {batch_2}\n",
    "\n",
    "3) ИСТОЧНИК 3:\n",
    "- {type_of_source3}\n",
    "- {link_to_source3}\n",
    "- {batch_3}\n",
    "\n",
    "### INSTRUCTION ###\n",
    "На основании приведенных данных категории «ТЕКСТ» дай исчерпывающий ответ на\n",
    "приведенный ниже вопрос:\n",
    "- {QUESTION}\n",
    "\"\"\"\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "### ROLE ###\n",
    "Ты - дружелюбный ассистент Центрального банка Российской Федерации. \n",
    "Исчерпывающе отвечай клиентам на возникшие вопросы. Если из контекста \n",
    "невозможно дать ответ на вопрос, пиши «Я не могу ответить на этот вопрос».\"\"\"\n",
    "\n",
    "def ask_chatbot(question):\n",
    "    gc.collect()\n",
    "    query = prep_query(question)\n",
    "    \n",
    "    result = bm25_ensemble_with_crossenc_answer(query=query, client=client, emb_func=emb_func, bm25_n_results=15, cr_enc_n_results=3, limit_knn=100, knn_docs_window=1)\n",
    "\n",
    "    type_of_source1, type_of_source2, type_of_source3  = '', '', ''\n",
    "    link_to_source1, link_to_source2, link_to_source3 = '', '', ''\n",
    "    batch_1, batch_2, batch_3 = '', '', ''\n",
    "\n",
    "\n",
    "    for idx, batch in enumerate(start=1, iterable=result):\n",
    "        if idx==1:\n",
    "            if batch[5]:\n",
    "                type_of_source1 = 'ТАБЛИЦА'\n",
    "            else:\n",
    "                type_of_source1 = 'ТЕКСТ'\n",
    "            link_to_source1 = batch[2]\n",
    "            batch_1 = batch[3]\n",
    "\n",
    "        if idx==2:\n",
    "            if batch[5]:\n",
    "                type_of_source2 = 'ТАБЛИЦА'\n",
    "            else:\n",
    "                type_of_source2 = 'ТЕКСТ'\n",
    "            link_to_source2 = batch[2]\n",
    "            batch_2 = batch[3]\n",
    "\n",
    "        if idx==3:\n",
    "            if batch[5]:\n",
    "                type_of_source3 = 'ТАБЛИЦА'\n",
    "            else:\n",
    "                type_of_source3 = 'ТЕКСТ'\n",
    "            link_to_source3 = batch[2]\n",
    "            batch_3 = batch[3]\n",
    "\n",
    "\n",
    "    formatted_rag_prompt = rag_prompt.format(\n",
    "        type_of_source1=type_of_source1,\n",
    "        link_to_source1=link_to_source1,\n",
    "        batch_1=batch_1,\n",
    "        type_of_source2=type_of_source2,\n",
    "        link_to_source2=link_to_source2,\n",
    "        batch_2=batch_2,\n",
    "        type_of_source3=type_of_source3,\n",
    "        link_to_source3=link_to_source3,\n",
    "        batch_3=batch_3,\n",
    "        QUESTION=question\n",
    "    )\n",
    "\n",
    "    answer = message_llm(system_prompt, formatted_rag_prompt)\n",
    "    \n",
    "    return f\"{answer}\\nИсточники: \\n{link_to_source1}, \\n{link_to_source2}, \\n{link_to_source3}\"\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=ask_chatbot,\n",
    "    inputs=\"text\",\n",
    "    outputs=\"text\",\n",
    "    title=\"Чат с виртуальным помощником - SCOOF DEVELOPERS\",\n",
    "    description=\"Введите ваше сообщение и получите ответ от модели:\"\n",
    ")\n",
    "\n",
    "# Запуск интерфейса\n",
    "iface.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58bc4c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50b393a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
